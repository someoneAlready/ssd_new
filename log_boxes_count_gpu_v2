Using mxnet as:
<module 'mxnet' from '/media/cgangee/OTHERS/incubator-mxnet/python/mxnet/__init__.pyc'>
Warning: using pre-installed version of mxnet may cause unexpected error...
(export MXNET_EXAMPLE_SSD_DISABLE_PRE_INSTALLED=1) to prevent loading pre-installed mxnet.
args.network = mobilenet
args.train_path = /home/cgangee/code/ssd/data/psdb/val.rec
args.num_class = 4
args.batch_size = 32
args.data_shape = 300
args.mean_r = 123
args.mean_g = 117
args.mean_b = 104
args.resume = -1
args.finetune = 1
args.pretrained = /home/cgangee/code/ssd/model/mobilenet-ssd-512
args.epoch = 1
args.prefix = /home/cgangee/code/ssd/output/psdbMobileNet/ssd
ctx = [gpu(0)]
args.begin_epoch = 0
args.end_epoch = 240
args.frequent = 20
args.learning_rate = 0.004
args.momentum = 0.9
args.weight_decay = 0.0005
args.lr_refactor_step = 80, 160
args.lr_refactor_ratio = 0.1
ctx = [gpu(0)]
args.val_path = /home/cgangee/code/ssd/data/psdb/val.rec
args.min_neg_samples = 0
args.num_example = 16551
class_names = ['pedestrian', 'head', 'head-shouler', 'upper-body']
args.label_width = 1200
args.freeze_pattern = ^(conv1_|conv2_).*
args.monitor = 0
args.monitor_pattern = .*
args.log_file = train.log
args.nms_thresh = 0.45
args.nms_topk = 400
args.force_nms = False
args.overlap_thresh = 0.5
args.use_difficult = False
args.use_voc07_metric = True
args.optimizer = sgd
args.tensorboard = False
{'shuffle': False, 'max_crop_overlaps': [1.0, 1.0, 1.0, 1.0, 1.0], 'max_crop_sample_coverages': [1.0, 1.0, 1.0, 1.0, 1.0], 'max_random_hue': 18, 'seed': 233, 'random_hue_prob': 0.5, 'preprocess_threads': 48, 'max_random_contrast': 0.5, 'max_random_saturation': 32, 'rand_mirror_prob': 0.0, 'rand_crop_prob': 0.0, 'max_pad_scale': 4.0, 'random_contrast_prob': 0.5, 'min_crop_scales': [0.3, 0.3, 0.3, 0.3, 0.3], 'rand_pad_prob': 0.0, 'min_crop_overlaps': [0.1, 0.3, 0.5, 0.7, 0.9], 'max_crop_object_coverages': [1.0, 1.0, 1.0, 1.0, 1.0], 'max_random_illumination': 32, 'max_crop_trials': [25, 25, 25, 25, 25], 'random_saturation_prob': 0.5, 'crop_emit_mode': 'center', 'min_crop_object_coverages': [0.0, 0.0, 0.0, 0.0, 0.0], 'min_crop_aspect_ratios': [0.5, 0.5, 0.5, 0.5, 0.5], 'inter_method': 10, 'random_illumination_prob': 0.5, 'fill_value': 127, 'max_crop_scales': [1.0, 1.0, 1.0, 1.0, 1.0], 'min_crop_sample_coverages': [0.0, 0.0, 0.0, 0.0, 0.0], 'num_crop_sampler': 5, 'max_crop_aspect_ratios': [2.0, 2.0, 2.0, 2.0, 2.0]}
[17:25:55] src/io/iter_image_det_recordio.cc:281: ImageDetRecordIOParser: /home/cgangee/code/ssd/data/psdb/val.rec, use 7 threads for decoding..
[17:25:55] src/io/iter_image_det_recordio.cc:334: ImageDetRecordIOParser: /home/cgangee/code/ssd/data/psdb/val.rec, label padding width: 1200
{'random_contrast_prob': 0.0, 'preprocess_threads': 32, 'shuffle': False, 'max_random_contrast': 0.5, 'max_random_illumination': 32, 'random_illumination_prob': 0.0, 'max_random_saturation': 32, 'fill_value': 127, 'rand_mirror_prob': 0, 'num_crop_sampler': 0, 'max_random_hue': 18, 'seed': 0, 'random_saturation_prob': 0.0, 'rand_crop_prob': 0.0, 'random_hue_prob': 0.0, 'max_pad_scale': 1.0, 'rand_pad_prob': 0.0}
[17:25:56] src/io/iter_image_det_recordio.cc:281: ImageDetRecordIOParser: /home/cgangee/code/ssd/data/psdb/val.rec, use 7 threads for decoding..
[17:25:56] src/io/iter_image_det_recordio.cc:334: ImageDetRecordIOParser: /home/cgangee/code/ssd/data/psdb/val.rec, label padding width: 1200
INFO:root:Start finetuning with (gpu(0)) from epoch 1
[[0.14999999999999999], [0.29999999999999999], [0.44999999999999996], [0.59999999999999998], [0.75], [0.90000000000000002]]
[17:25:57] src/nnvm/legacy_json_util.cc:190: Loading symbol saved by previous version v0.12.0. Attempting to upgrade...
[17:25:57] src/nnvm/legacy_json_util.cc:198: Symbol successfully upgraded!
INFO:root:Removed conv_14_relu_loc_pred_conv_bias
INFO:root:Removed multi_feat_2_conv_3x3_relu_loc_pred_conv_weight
INFO:root:Removed multi_feat_5_conv_3x3_relu_cls_pred_conv_bias
INFO:root:Removed multi_feat_3_conv_3x3_relu_cls_pred_conv_bias
INFO:root:Removed conv_12_relu_loc_pred_conv_weight
INFO:root:Removed multi_feat_5_conv_3x3_relu_cls_pred_conv_weight
INFO:root:Removed multi_feat_4_conv_3x3_relu_loc_pred_conv_bias
INFO:root:Removed multi_feat_4_conv_3x3_relu_loc_pred_conv_weight
INFO:root:Removed multi_feat_5_conv_3x3_relu_loc_pred_conv_weight
INFO:root:Removed conv_12_relu_cls_pred_conv_bias
INFO:root:Removed multi_feat_3_conv_3x3_relu_cls_pred_conv_weight
INFO:root:Removed multi_feat_2_conv_3x3_relu_cls_pred_conv_weight
INFO:root:Removed multi_feat_3_conv_3x3_relu_loc_pred_conv_bias
INFO:root:Removed multi_feat_2_conv_3x3_relu_cls_pred_conv_bias
INFO:root:Removed multi_feat_4_conv_3x3_relu_cls_pred_conv_weight
INFO:root:Removed multi_feat_3_conv_3x3_relu_loc_pred_conv_weight
INFO:root:Removed conv_12_relu_cls_pred_conv_weight
INFO:root:Removed conv_12_relu_loc_pred_conv_bias
INFO:root:Removed conv_14_relu_cls_pred_conv_bias
INFO:root:Removed multi_feat_2_conv_3x3_relu_loc_pred_conv_bias
INFO:root:Removed multi_feat_4_conv_3x3_relu_cls_pred_conv_bias
INFO:root:Removed conv_14_relu_loc_pred_conv_weight
INFO:root:Removed multi_feat_5_conv_3x3_relu_loc_pred_conv_bias
INFO:root:Removed conv_14_relu_cls_pred_conv_weight
[17:26:01] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
109
121
107
115
126
117
112
131
126
131
134
132
139
141
143
155
147
142
142
146
144
146
149
150
151
150
157
149
171
156
159
172
165
176
167
166
162
160
161
183
168
166
173
170
174
179
164
179
176
169
177
171
192
192
192
175
188
183
193
190
186
184
178
184
188
204
195
201
194
187
191
207
184
186
208
189
191
201
195
205
204
211
192
197
212
188
209
202
200
209
211
200
197
196
217
203
221
208
204
200
211
219
205
213
209
212
209
212
218
207
208
214
211
206
216
198
214
201
212
205
220
211
208
218
222
218
225
210
214
223
220
214
214
218
208
227
205
223
213
221
214
222
214
210
215
218
213
219
219
224
212
206
221
218
227
216
210
218
211
227
230
210
213
218
222
211
219
218
222
209
220
207
224
220
216
219
218
219
216
221
214
216
215
203
220
217
222
217
210
218
222
214
226
213
226
211
222
208
219
223
213
221
224
217
220
223
220
226
210
218
200
216
212
208
219
210
219
216
213
219
224
232
204
220
217
217
222
225
212
209
228
208
216
203
207
203
198
214
211
209
211
199
217
213
217
211
212
206
204
200
202
205
204
203
199
213
200
213
198
210
207
201
204
210
208
195
194
206
195
203
192
194
202
210
201
183
199
200
184
204
189
188
197
190
186
185
186
189
181
186
186
179
196
186
178
188
173
187
185
180
188
175
176
172
179
179
168
179
180
165
180
169
169
158
178
166
167
171
58
62
57
59
59
61
60
61
60
62
60
59
60
59
59
58
62
60
60
59
61
60
61
59
63
62
61
62
63
62
61
61
62
62
64
62
62
61
62
64
61
63
63
62
62
63
63
63
63
62
64
63
63
63
62
61
61
63
64
62
61
62
64
61
63
64
64
62
62
62
62
63
64
62
63
64
62
61
64
64
63
64
63
62
63
64
63
63
64
63
63
64
64
62
64
64
64
63
63
63
63
63
62
61
62
63
63
62
62
64
63
64
64
64
64
64
62
63
61
61
64
63
64
64
64
64
62
63
64
64
63
62
64
64
64
64
63
64
63
64
64
64
63
64
64
64
64
63
64
62
64
63
63
64
64
62
64
64
63
64
64
62
64
64
64
64
62
64
64
64
64
63
64
63
64
62
63
64
63
63
64
64
64
64
63
63
62
64
64
63
63
63
63
64
64
63
64
64
64
64
63
64
61
63
63
64
64
64
63
64
64
64
64
63
64
64
64
64
64
64
63
63
62
64
63
63
64
64
64
64
64
63
64
64
64
63
63
64
63
63
64
63
64
64
63
64
64
63
63
64
64
63
61
63
64
64
64
62
63
63
64
64
63
63
62
64
63
63
62
63
63
63
63
64
64
64
62
64
63
64
64
63
61
64
63
63
62
63
63
64
63
64
63
64
63
64
64
64
62
63
62
63
62
62
64
63
63
64
64
63
62
63
63
64
64
62
63
63
76
75
80
73
81
77
79
76
78
78
76
73
77
75
79
74
80
77
78
74
78
78
74
76
76
80
77
74
80
78
78
79
75
79
80
77
79
74
78
77
80
74
75
77
80
80
77
80
78
78
79
75
79
75
80
80
78
76
76
79
77
77
77
78
77
79
79
78
78
78
77
78
79
77
75
79
76
72
80
75
79
76
80
77
82
76
77
78
79
79
78
78
77
80
76
78
78
76
75
80
75
77
78
79
78
80
77
81
80
82
82
75
79
80
78
78
77
82
79
79
81
79
79
80
76
82
77
78
74
78
77
79
79
74
78
79
76
78
79
75
77
77
78
77
79
78
80
71
79
78
77
77
76
77
79
76
75
76
78
79
76
83
79
74
78
82
70
78
78
78
78
76
77
77
77
78
70
78
79
79
75
74
76
73
77
78
77
77
80
76
77
79
79
73
77
78
75
74
76
80
72
76
76
75
75
78
81
73
75
79
70
79
79
75
76
71
71
75
78
73
79
76
70
71
70
80
76
70
71
71
76
67
75
71
74
78
77
74
72
69
74
70
80
72
73
77
73
73
74
72
74
66
70
72
69
69
69
73
69
69
70
71
65
70
72
66
65
73
67
66
68
72
62
69
70
67
64
61
63
62
69
67
70
72
66
64
64
66
63
64
61
67
65
66
65
63
59
58
63
64
60
62
64
57
65
61
61
61
53
59
56
57
57
53
57
58
54
60
22
24
24
28
25
23
21
20
25
25
27
26
26
23
24
25
25
25
23
26
24
25
22
22
22
25
25
22
24
26
24
23
19
26
22
26
22
21
20
24
21
25
24
27
22
25
24
25
24
22
21
21
23
23
23
21
22
23
23
20
22
23
22
24
21
22
25
23
21
24
22
23
20
24
22
24
23
23
25
25
22
26
21
24
26
21
25
23
20
23
19
22
24
24
22
20
20
22
23
20
22
23
23
17
22
21
22
18
22
18
20
22
22
22
20
21
21
21
23
21
22
21
21
23
16
23
16
20
22
20
21
22
25
22
22
20
20
20
22
22
19
23
21
18
21
22
20
21
21
20
18
18
17
18
20
18
19
18
20
17
20
17
18
21
18
18
16
20
20
16
21
19
15
16
18
17
16
17
16
17
15
18
19
18
18
18
16
17
18
16
17
15
16
15
17
16
14
17
16
16
16
14
17
17
15
16
16
14
16
15
16
16
18
16
16
14
16
17
14
16
14
17
14
17
15
16
15
15
15
14
16
15
15
15
16
14
15
14
14
16
14
16
16
15
15
14
16
15
16
17
14
14
14
14
15
16
15
15
15
15
15
17
14
14
14
14
14
15
14
14
14
14
14
16
15
14
14
14
14
15
14
15
15
15
15
14
14
14
15
14
15
15
14
14
15
16
16
15
14
14
14
15
14
14
15
15
14
14
15
14
15
16
14
15
14
14
15
14
18
18
19
18
18
18
18
18
18
18
18
18
18
18
18
18
19
19
18
18
18
18
19
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
18
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
9
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
9
10
10
10
10
10
10
10
10
10
9
9
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
9
10
10
10
10
10
9
8
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
10
9
9
10
10
8
10
10
10
9
8
9
9
8
10
10
10
10
10
10
10
10
9
10
9
10
9
9
10
10
10
8
9
9
10
8
7
10
9
8
9
9
9
10
9
10
9
10
8
8
7
7
8
7
7
7
7
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
5
6
6
6
5
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
5
6
5
6
6
6
6
6
5
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
6
5
5
6
6
6
6
6
6
6
6
6
6
5
6
6
5
6
5
5
6
6
6
6
6
5
6
5
6
6
5
6
6
6
6
4
5
4
5
5
4
4
6
5
4
6
6
5
6
6
5
5
5
4
6
6
4
6
4
6
6
5
5
6
5
4
6
5
6
5
5
5
4
5
4
5
6
4
3
4
4
4
3
5
5
5
3
6
5
3
5
4
4
3
2
5
4
5
5
3
5
2
4
4
2
3
4
3
4
4
4
3
5
3
3
4
2
4
3
3
3
5
2
3
2
2
3
3
3
2
2
2
2
2
2
2
4
2
3
2
3
4
3
3
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
